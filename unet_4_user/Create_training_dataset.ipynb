{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training dataset\n",
    "\n",
    "This notebook use a simple workflow to create a dataset necessary for the training the model for UnAxSeg (Unet for Axon Segmentation).\n",
    "Important comment, the structure of the starting folder need to be precisely respected in order to avoid eventual bugs.\n",
    "\n",
    "Contents\n",
    "\n",
    "1- Descrition of the folder structure\n",
    "2- Explanation of the workflow\n",
    "4- Detail \n",
    "3- Run it in one line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Description of the folder structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a 'sample' correspond to one light microscopy image,the groundtruth and pixel size txtfile.\n",
    "- __image.png__ should be a RGB image (blue staining image)\n",
    "- __mask.png__ is the groundtruth manually segmentated image (the procedure for manual segmentation is decribed here (procedure for manual segmenation ./procedure). mask.png should be a grayscale image with 3 color (white for the axon, gray for the myelin and black for the background.\n",
    "- __pixel_size_micrometer.txt__ (optional: not in use at the moment important to have it to keep tract of the resolution. Later we will put a rescaling functionality)\n",
    "\n",
    "\n",
    "the structure should be :\n",
    "    ./Dataset\n",
    "        /test:\n",
    "            - sample_1 :\n",
    "                - image.png\n",
    "                - mask.png \n",
    "                - pixel_size_micrometer.txt\n",
    "             - sample_2 :\n",
    "                - image.png\n",
    "                - mask.png \n",
    "                - pixel_size_micrometer.txt\n",
    "                \n",
    "        /train_validation:\n",
    "            - sample_3:\n",
    "                - image.png\n",
    "                - mask.png\n",
    "                - pixel_size_micrometer.txt    \n",
    "            - sample_4:...\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Explanation of workflow\n",
    "\n",
    "1. Convert the image.png in grayscale and inverse it (fig)\n",
    "2. Create a folder /Dataset/Patch_for_Training\n",
    "3. Split each image.png (and correponding mask.png) from each sample in a list of patches (patch size: 256 or 512 or...) and store them in /Dataset/Patch_for_Training with name : image_0.npng, mask_0.png...image_100.npng, mask_100.png....\n",
    "4. Split randomly the list of pair image/mask in 2 folders  /Dataset/Patch_for_Training/train and /Dataset/Patch_for_Training/validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code  part\n",
    "\n",
    "Everything you need is store in Utility_create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utility.Utility_Dataset as Utility_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Run by blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the parent folder /Dataset where you have /test and /train_validation\n",
    "Parent_folder = './Data/Dataset_demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder /Dataset/Patch_for_Training\n",
    "# and create the patches pair and save then in /Dataset/Patch_for_Training\n",
    "# you can choose patch_size and overlap (between patches). patch_size need to match network input size\n",
    "# Return Patch_for_Trainin_folder: location './Dataset/Patch_for_Training'\n",
    "\n",
    "Patch_for_Training_folder = Utility_Dataset.Create_patches_for_dataset(Parent_folder, patch_size = 256, overlap = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split patches into train and validation\n",
    "# Create /Dataset/Patch_for_Training/train and /Dataset/Patch_for_Training/validation\n",
    "# you can choose the split \n",
    "# use a specific value in seed to reproduce the randomization dduring the split\n",
    "\n",
    "Utility_Dataset.split_train_validation(Patch_for_Training_folder, split=(0.8,0.2), seed = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Run in one line\n",
    "\n",
    "__don't run it if you already run cells from 3-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose (if you don't know leave like this:\n",
    "patch_size = 256\n",
    "overlap = 25\n",
    "split = (0.8,0.2) # (train, validation)\n",
    "seed = None\n",
    "Utility_Dataset.Create_training_dataset(patch_size=patch_size, overlap = overlap, split=split, seed =seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
